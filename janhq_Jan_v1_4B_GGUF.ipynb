{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Troyanovsky/Local-LLM-Comparison-Colab-UI/blob/main/janhq_Jan_v1_4B_GGUF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNkpBtLvuTOp"
      },
      "source": [
        "## janhq_Jan-v1-4B-GGUF WebUI\n",
        "\n",
        "1. Run the following cell, takes ~5 min\n",
        "(You may need to confirm to proceed by typing \"Y\")\n",
        "2. Click the gradio link at the bottom\n",
        "\n",
        "Recommended params:\n",
        "```\n",
        "temperature: 0.6\n",
        "top_p: 0.95\n",
        "top_k: 20\n",
        "min_p: 0.0\n",
        "max_tokens: 2048\n",
        "```\n",
        "\n",
        "Note: This model is optimized for search & deep research. Toggle on \"Web Search\" for it to browse the web.\n",
        "\n",
        "Quantized model: https://huggingface.co/bartowski/janhq_Jan-v1-4B-GGUF\n",
        "\n",
        "Original model: https://huggingface.co/janhq/Jan-v1-4B\n",
        "\n",
        "Want to try other local LLMs? Check out this repo: https://github.com/Troyanovsky/Local-LLM-Comparison-Colab-UI/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D-MiHp_bveP6",
        "outputId": "f4b18da0-0ced-4c5c-c6ae-40fc3c21d1fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 126380 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "Cloning into 'text-generation-webui'...\n",
            "remote: Enumerating objects: 24383, done.\u001b[K\n",
            "remote: Total 24383 (delta 0), reused 0 (delta 0), pack-reused 24383 (from 1)\u001b[K\n",
            "Receiving objects: 100% (24383/24383), 29.93 MiB | 15.42 MiB/s, done.\n",
            "Resolving deltas: 100% (17694/17694), done.\n",
            "Note: switching to '45e2935e87f19aa3d5afec9a403203259cb1eacc'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "/content/text-generation-webui\n",
            "Ignoring triton-windows: markers 'platform_system == \"Windows\"' don't match your environment\n",
            "Ignoring llama-cpp-binaries: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
            "Collecting llama-cpp-binaries==0.36.0+cu124 (from -r requirements/full/requirements.txt (line 38))\n",
            "  Downloading https://github.com/oobabooga/llama-cpp-binaries/releases/download/v0.36.0/llama_cpp_binaries-0.36.0+cu124-py3-none-linux_x86_64.whl (645.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m645.3/645.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hIgnoring exllamav3: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
            "Collecting exllamav3==0.0.5+cu124.torch2.6.0 (from -r requirements/full/requirements.txt (line 40))\n",
            "  Downloading https://github.com/oobabooga/exllamav3/releases/download/v0.0.5/exllamav3-0.0.5+cu124.torch2.6.0-cp311-cp311-linux_x86_64.whl (72.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hIgnoring exllamav2: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
            "Collecting exllamav2==0.3.2+cu124.torch2.6.0 (from -r requirements/full/requirements.txt (line 42))\n",
            "  Downloading https://github.com/turboderp-org/exllamav2/releases/download/v0.3.2/exllamav2-0.3.2+cu124.torch2.6.0-cp311-cp311-linux_x86_64.whl (165.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hIgnoring exllamav2: markers 'platform_system == \"Linux\" and platform_machine != \"x86_64\"' don't match your environment\n",
            "Ignoring flash-attn: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
            "Collecting flash-attn==2.7.4.post1+cu12torch2.6cxx11abiFALSE (from -r requirements/full/requirements.txt (line 45))\n",
            "  Downloading https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.4.post1/flash_attn-2.7.4.post1+cu12torch2.6cxx11abiFALSE-cp311-cp311-linux_x86_64.whl (187.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.8/187.8 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate==1.8.* (from -r requirements/full/requirements.txt (line 1))\n",
            "  Downloading accelerate-1.8.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting bitsandbytes==0.46.* (from -r requirements/full/requirements.txt (line 2))\n",
            "  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Collecting colorama (from -r requirements/full/requirements.txt (line 3))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from -r requirements/full/requirements.txt (line 4)) (4.0.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements/full/requirements.txt (line 5)) (0.8.1)\n",
            "Collecting fastapi==0.112.4 (from -r requirements/full/requirements.txt (line 6))\n",
            "  Downloading fastapi-0.112.4-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting gradio==4.37.* (from -r requirements/full/requirements.txt (line 7))\n",
            "  Downloading gradio-4.37.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting html2text==2025.4.15 (from -r requirements/full/requirements.txt (line 8))\n",
            "  Downloading html2text-2025.4.15-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: jinja2==3.1.6 in /usr/local/lib/python3.11/dist-packages (from -r requirements/full/requirements.txt (line 9)) (3.1.6)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from -r requirements/full/requirements.txt (line 10)) (3.8.2)\n",
            "Collecting numpy==2.2.* (from -r requirements/full/requirements.txt (line 11))\n",
            "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements/full/requirements.txt (line 12)) (2.2.2)\n",
            "Collecting peft==0.16.* (from -r requirements/full/requirements.txt (line 13))\n",
            "  Downloading peft-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: Pillow>=9.5.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements/full/requirements.txt (line 14)) (11.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements/full/requirements.txt (line 15)) (5.9.5)\n",
            "Collecting pydantic==2.8.2 (from -r requirements/full/requirements.txt (line 16))\n",
            "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyPDF2==3.0.1 (from -r requirements/full/requirements.txt (line 17))\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting python-docx==1.1.2 (from -r requirements/full/requirements.txt (line 18))\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r requirements/full/requirements.txt (line 19)) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from -r requirements/full/requirements.txt (line 20)) (2.32.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from -r requirements/full/requirements.txt (line 21)) (13.9.4)\n",
            "Collecting safetensors==0.5.* (from -r requirements/full/requirements.txt (line 22))\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements/full/requirements.txt (line 23)) (1.16.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements/full/requirements.txt (line 24)) (0.2.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r requirements/full/requirements.txt (line 25)) (2.19.0)\n",
            "Requirement already satisfied: transformers==4.55.* in /usr/local/lib/python3.11/dist-packages (from -r requirements/full/requirements.txt (line 26)) (4.55.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements/full/requirements.txt (line 28)) (4.67.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r requirements/full/requirements.txt (line 29)) (0.21.1)\n",
            "Collecting flask_cloudflared==0.0.14 (from -r requirements/full/requirements.txt (line 32))\n",
            "  Downloading flask_cloudflared-0.0.14-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting sse-starlette==1.6.5 (from -r requirements/full/requirements.txt (line 33))\n",
            "  Downloading sse_starlette-1.6.5-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from -r requirements/full/requirements.txt (line 34)) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.8.*->-r requirements/full/requirements.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.8.*->-r requirements/full/requirements.txt (line 1)) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.8.*->-r requirements/full/requirements.txt (line 1)) (0.34.4)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi==0.112.4->-r requirements/full/requirements.txt (line 6))\n",
            "  Downloading starlette-0.38.6-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.112.4->-r requirements/full/requirements.txt (line 6)) (4.14.1)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==4.37.*->-r requirements/full/requirements.txt (line 7))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (5.5.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (0.6.1)\n",
            "Collecting gradio-client==1.0.2 (from gradio==4.37.*->-r requirements/full/requirements.txt (line 7))\n",
            "  Downloading gradio_client-1.0.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (0.28.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (6.5.2)\n",
            "Collecting markupsafe~=2.0 (from gradio==4.37.*->-r requirements/full/requirements.txt (line 7))\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (3.10.0)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (3.11.1)\n",
            "Collecting Pillow>=9.5.0 (from -r requirements/full/requirements.txt (line 14))\n",
            "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (0.12.8)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (2.10.0)\n",
            "Collecting tomlkit==0.12.0 (from gradio==4.37.*->-r requirements/full/requirements.txt (line 7))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (0.16.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (2.5.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (0.35.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.8.2->-r requirements/full/requirements.txt (line 16)) (0.7.0)\n",
            "Collecting pydantic-core==2.20.1 (from pydantic==2.8.2->-r requirements/full/requirements.txt (line 16))\n",
            "  Downloading pydantic_core-2.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx==1.1.2->-r requirements/full/requirements.txt (line 18)) (5.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.*->-r requirements/full/requirements.txt (line 26)) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.*->-r requirements/full/requirements.txt (line 26)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.55.*->-r requirements/full/requirements.txt (line 26)) (0.21.4)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.11/dist-packages (from flask_cloudflared==0.0.14->-r requirements/full/requirements.txt (line 32)) (3.1.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.0.2->gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (2025.3.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==1.0.2->gradio==4.37.*->-r requirements/full/requirements.txt (line 7))\n",
            "  Downloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements/full/requirements.txt (line 4)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements/full/requirements.txt (line 4)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements/full/requirements.txt (line 4)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements/full/requirements.txt (line 4)) (0.70.16)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements/full/requirements.txt (line 12)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements/full/requirements.txt (line 12)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements/full/requirements.txt (line 12)) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements/full/requirements.txt (line 20)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements/full/requirements.txt (line 20)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements/full/requirements.txt (line 20)) (2025.8.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->-r requirements/full/requirements.txt (line 21)) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->-r requirements/full/requirements.txt (line 21)) (2.19.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements/full/requirements.txt (line 25)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements/full/requirements.txt (line 25)) (1.74.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements/full/requirements.txt (line 25)) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements/full/requirements.txt (line 25)) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements/full/requirements.txt (line 25)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements/full/requirements.txt (line 25)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements/full/requirements.txt (line 25)) (3.1.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements/full/requirements.txt (line 29)) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements/full/requirements.txt (line 29)) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements/full/requirements.txt (line 29)) (4.3.8)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r requirements/full/requirements.txt (line 29)) (2.34.1)\n",
            "Collecting ninja (from exllamav3==0.0.5+cu124.torch2.6.0->-r requirements/full/requirements.txt (line 40))\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: marisa-trie in /usr/local/lib/python3.11/dist-packages (from exllamav3==0.0.5+cu124.torch2.6.0->-r requirements/full/requirements.txt (line 40)) (1.2.1)\n",
            "Collecting kbnf>=0.4.2 (from exllamav3==0.0.5+cu124.torch2.6.0->-r requirements/full/requirements.txt (line 40))\n",
            "  Downloading kbnf-0.4.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting formatron>=0.5.0 (from exllamav3==0.0.5+cu124.torch2.6.0->-r requirements/full/requirements.txt (line 40))\n",
            "  Downloading formatron-0.5.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting fastparquet (from exllamav2==0.3.2+cu124.torch2.6.0->-r requirements/full/requirements.txt (line 42))\n",
            "  Downloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (2.1.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask_cloudflared==0.0.14->-r requirements/full/requirements.txt (line 32)) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask_cloudflared==0.0.14->-r requirements/full/requirements.txt (line 32)) (2.2.0)\n",
            "Collecting general-sam<2,>=1 (from formatron>=0.5.0->exllamav3==0.0.5+cu124.torch2.6.0->-r requirements/full/requirements.txt (line 40))\n",
            "  Downloading general_sam-1.0.2-cp310-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: frozendict<3,>=2 in /usr/local/lib/python3.11/dist-packages (from formatron>=0.5.0->exllamav3==0.0.5+cu124.torch2.6.0->-r requirements/full/requirements.txt (line 40)) (2.4.6)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements/full/requirements.txt (line 4)) (3.12.15)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements/full/requirements.txt (line 29)) (4.0.12)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate==1.8.*->-r requirements/full/requirements.txt (line 1)) (1.1.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->-r requirements/full/requirements.txt (line 21)) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib~=3.0->gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (3.2.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.8.*->-r requirements/full/requirements.txt (line 1)) (3.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate==1.8.*->-r requirements/full/requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate==1.8.*->-r requirements/full/requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate==1.8.*->-r requirements/full/requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate==1.8.*->-r requirements/full/requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate==1.8.*->-r requirements/full/requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate==1.8.*->-r requirements/full/requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate==1.8.*->-r requirements/full/requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate==1.8.*->-r requirements/full/requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate==1.8.*->-r requirements/full/requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.8.*->-r requirements/full/requirements.txt (line 1)) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2.0.0->accelerate==1.8.*->-r requirements/full/requirements.txt (line 1))\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.8.*->-r requirements/full/requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate==1.8.*->-r requirements/full/requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.8.*->-r requirements/full/requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.8.*->-r requirements/full/requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate==1.8.*->-r requirements/full/requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (1.5.4)\n",
            "Requirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.11/dist-packages (from fastparquet->exllamav2==0.3.2+cu124.torch2.6.0->-r requirements/full/requirements.txt (line 42)) (2.11.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements/full/requirements.txt (line 4)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements/full/requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements/full/requirements.txt (line 4)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements/full/requirements.txt (line 4)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements/full/requirements.txt (line 4)) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements/full/requirements.txt (line 4)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirements/full/requirements.txt (line 4)) (1.20.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.24.1->gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements/full/requirements.txt (line 29)) (5.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.37.*->-r requirements/full/requirements.txt (line 7)) (0.27.0)\n",
            "Downloading accelerate-1.8.1-py3-none-any.whl (365 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.112.4-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-4.37.2-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading html2text-2025.4.15-py3-none-any.whl (34 kB)\n",
            "Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.16.0-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.3/472.3 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.9/423.9 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask_cloudflared-0.0.14-py3-none-any.whl (6.4 kB)\n",
            "Downloading sse_starlette-1.6.5-py3-none-any.whl (9.6 kB)\n",
            "Downloading gradio_client-1.0.2-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.2/318.2 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading formatron-0.5.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kbnf-0.4.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading starlette-0.38.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.6/130.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading general_sam-1.0.2-cp310-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (290 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.6/290.6 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: websockets, tomlkit, safetensors, python-docx, PyPDF2, pydantic-core, Pillow, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, ninja, markupsafe, llama-cpp-binaries, html2text, general-sam, colorama, aiofiles, starlette, pydantic, nvidia-cusparse-cu12, nvidia-cudnn-cu12, kbnf, sse-starlette, nvidia-cusolver-cu12, gradio-client, fastparquet, fastapi, formatron, flask_cloudflared, gradio, flash-attn, exllamav3, exllamav2, bitsandbytes, accelerate, peft\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.13.3\n",
            "    Uninstalling tomlkit-0.13.3:\n",
            "      Successfully uninstalled tomlkit-0.13.3\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.6.2\n",
            "    Uninstalling safetensors-0.6.2:\n",
            "      Successfully uninstalled safetensors-0.6.2\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: aiofiles\n",
            "    Found existing installation: aiofiles 24.1.0\n",
            "    Uninstalling aiofiles-24.1.0:\n",
            "      Successfully uninstalled aiofiles-24.1.0\n",
            "  Attempting uninstall: starlette\n",
            "    Found existing installation: starlette 0.47.2\n",
            "    Uninstalling starlette-0.47.2:\n",
            "      Successfully uninstalled starlette-0.47.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.7\n",
            "    Uninstalling pydantic-2.11.7:\n",
            "      Successfully uninstalled pydantic-2.11.7\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.11.1\n",
            "    Uninstalling gradio_client-1.11.1:\n",
            "      Successfully uninstalled gradio_client-1.11.1\n",
            "  Attempting uninstall: fastapi\n",
            "    Found existing installation: fastapi 0.116.1\n",
            "    Uninstalling fastapi-0.116.1:\n",
            "      Successfully uninstalled fastapi-0.116.1\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.42.0\n",
            "    Uninstalling gradio-5.42.0:\n",
            "      Successfully uninstalled gradio-5.42.0\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.10.0\n",
            "    Uninstalling accelerate-1.10.0:\n",
            "      Successfully uninstalled accelerate-1.10.0\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.17.0\n",
            "    Uninstalling peft-0.17.0:\n",
            "      Successfully uninstalled peft-0.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yfinance 0.2.65 requires websockets>=13.0, but you have websockets 11.0.3 which is incompatible.\n",
            "dataproc-spark-connect 0.8.3 requires websockets>=14.0, but you have websockets 11.0.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
            "google-genai 1.29.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 11.0.3 which is incompatible.\n",
            "albumentations 2.0.8 requires pydantic>=2.9.2, but you have pydantic 2.8.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-10.4.0 PyPDF2-3.0.1 accelerate-1.8.1 aiofiles-23.2.1 bitsandbytes-0.46.1 colorama-0.4.6 exllamav2-0.3.2+cu124.torch2.6.0 exllamav3-0.0.5+cu124.torch2.6.0 fastapi-0.112.4 fastparquet-2024.11.0 flash-attn-2.7.4.post1 flask_cloudflared-0.0.14 formatron-0.5.0 general-sam-1.0.2 gradio-4.37.2 gradio-client-1.0.2 html2text-2025.4.15 kbnf-0.4.2 llama-cpp-binaries-0.36.0+cu124 markupsafe-2.1.5 ninja-1.13.0 numpy-2.2.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 peft-0.16.0 pydantic-2.8.2 pydantic-core-2.20.1 python-docx-1.1.2 safetensors-0.5.3 sse-starlette-1.6.5 starlette-0.38.6 tomlkit-0.12.0 websockets-11.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "3f41f0e2a44542b6a5599ffe6b98cf4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "f801f9|\u001b[1;32mOK\u001b[0m  |   192MiB/s|/content/text-generation-webui/user_data/models/janhq_Jan-v1-4B-Q8_0.gguf\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n",
            "/content/text-generation-webui\n",
            "\u001b[2;36m07:42:11-213833\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting Text generation web UI                        \n",
            "\u001b[2;36m07:42:11-461228\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading \u001b[32m\"janhq_Jan-v1-4B-Q8_0.gguf\"\u001b[0m                    \n",
            "\u001b[2;36m07:42:11-470046\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Using \u001b[33mgpu_layers\u001b[0m=\u001b[1;36m10000\u001b[0m | \u001b[33mctx_size\u001b[0m=\u001b[1;36m8192\u001b[0m |               \n",
            "\u001b[2;36m                \u001b[0m         \u001b[33mcache_type\u001b[0m=\u001b[35mfp16\u001b[0m                                        \n",
            "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
            "ggml_cuda_init: found 1 CUDA devices:\n",
            "  Device 0: Tesla T4, compute capability 7.5, VMM: yes\n",
            "build: 1 (e28e303) with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "system info: n_threads = 1, n_threads_batch = 1, total_threads = 2\n",
            "\n",
            "system_info: n_threads = 1 (n_threads_batch = 1) / 2 | CUDA : ARCHS = 500,520,530,600,610,620,700,720,750,800,860,870,890,900 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
            "\n",
            "Web UI is disabled\n",
            "main: binding port with default address family\n",
            "main: HTTP server is listening, hostname: 127.0.0.1, port: 34647, http threads: 3\n",
            "main: loading model\n",
            "llama_model_load_from_file_impl: using device CUDA0 (Tesla T4) - 14992 MiB free\n",
            "llama_model_loader: loaded meta data with 39 key-value pairs and 398 tensors from user_data/models/janhq_Jan-v1-4B-Q8_0.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = qwen3\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Jan v1 4B\n",
            "llama_model_loader: - kv   3:                           general.basename str              = Jan-v1\n",
            "llama_model_loader: - kv   4:                         general.size_label str              = 4B\n",
            "llama_model_loader: - kv   5:                            general.license str              = apache-2.0\n",
            "llama_model_loader: - kv   6:                   general.base_model.count u32              = 1\n",
            "llama_model_loader: - kv   7:                  general.base_model.0.name str              = Qwen3 4B Thinking 2507\n",
            "llama_model_loader: - kv   8:               general.base_model.0.version str              = 2507\n",
            "llama_model_loader: - kv   9:          general.base_model.0.organization str              = Qwen\n",
            "llama_model_loader: - kv  10:              general.base_model.0.repo_url str              = https://huggingface.co/Qwen/Qwen3-4B-...\n",
            "llama_model_loader: - kv  11:                               general.tags arr[str,1]       = [\"text-generation\"]\n",
            "llama_model_loader: - kv  12:                          general.languages arr[str,1]       = [\"en\"]\n",
            "llama_model_loader: - kv  13:                          qwen3.block_count u32              = 36\n",
            "llama_model_loader: - kv  14:                       qwen3.context_length u32              = 262144\n",
            "llama_model_loader: - kv  15:                     qwen3.embedding_length u32              = 2560\n",
            "llama_model_loader: - kv  16:                  qwen3.feed_forward_length u32              = 9728\n",
            "llama_model_loader: - kv  17:                 qwen3.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv  18:              qwen3.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  19:                       qwen3.rope.freq_base f32              = 5000000.000000\n",
            "llama_model_loader: - kv  20:     qwen3.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  21:                 qwen3.attention.key_length u32              = 128\n",
            "llama_model_loader: - kv  22:               qwen3.attention.value_length u32              = 128\n",
            "llama_model_loader: - kv  23:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  24:                         tokenizer.ggml.pre str              = qwen2\n",
            "llama_model_loader: - kv  25:                      tokenizer.ggml.tokens arr[str,151936]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  26:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  27:                      tokenizer.ggml.merges arr[str,151387]  = [\"Ġ Ġ\", \"ĠĠ ĠĠ\", \"i n\", \"Ġ t\",...\n",
            "llama_model_loader: - kv  28:                tokenizer.ggml.eos_token_id u32              = 151645\n",
            "llama_model_loader: - kv  29:            tokenizer.ggml.padding_token_id u32              = 151643\n",
            "llama_model_loader: - kv  30:                tokenizer.ggml.bos_token_id u32              = 151643\n",
            "llama_model_loader: - kv  31:               tokenizer.ggml.add_bos_token bool             = false\n",
            "llama_model_loader: - kv  32:                    tokenizer.chat_template str              = {%- if tools %}\\n    {{- '<|im_start|>...\n",
            "llama_model_loader: - kv  33:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  34:                          general.file_type u32              = 7\n",
            "llama_model_loader: - kv  35:                      quantize.imatrix.file str              = /models_out/Jan-v1-4B-GGUF/janhq_Jan-...\n",
            "llama_model_loader: - kv  36:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav5.txt\n",
            "llama_model_loader: - kv  37:             quantize.imatrix.entries_count u32              = 252\n",
            "llama_model_loader: - kv  38:              quantize.imatrix.chunks_count u32              = 1184\n",
            "llama_model_loader: - type  f32:  145 tensors\n",
            "llama_model_loader: - type q8_0:  253 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q8_0\n",
            "print_info: file size   = 3.98 GiB (8.50 BPW) \n",
            "load: printing all EOG tokens:\n",
            "load:   - 151643 ('<|endoftext|>')\n",
            "load:   - 151645 ('<|im_end|>')\n",
            "load:   - 151662 ('<|fim_pad|>')\n",
            "load:   - 151663 ('<|repo_name|>')\n",
            "load:   - 151664 ('<|file_sep|>')\n",
            "load: special tokens cache size = 26\n",
            "load: token to piece cache size = 0.9311 MB\n",
            "print_info: arch             = qwen3\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 262144\n",
            "print_info: n_embd           = 2560\n",
            "print_info: n_layer          = 36\n",
            "print_info: n_head           = 32\n",
            "print_info: n_head_kv        = 8\n",
            "print_info: n_rot            = 128\n",
            "print_info: n_swa            = 0\n",
            "print_info: is_swa_any       = 0\n",
            "print_info: n_embd_head_k    = 128\n",
            "print_info: n_embd_head_v    = 128\n",
            "print_info: n_gqa            = 4\n",
            "print_info: n_embd_k_gqa     = 1024\n",
            "print_info: n_embd_v_gqa     = 1024\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-06\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 9728\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = -1\n",
            "print_info: rope type        = 2\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 5000000.0\n",
            "print_info: freq_scale_train = 1\n",
            "print_info: n_ctx_orig_yarn  = 262144\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: model type       = 4B\n",
            "print_info: model params     = 4.02 B\n",
            "print_info: general.name     = Jan v1 4B\n",
            "print_info: vocab type       = BPE\n",
            "print_info: n_vocab          = 151936\n",
            "print_info: n_merges         = 151387\n",
            "print_info: BOS token        = 151643 '<|endoftext|>'\n",
            "print_info: EOS token        = 151645 '<|im_end|>'\n",
            "print_info: EOT token        = 151645 '<|im_end|>'\n",
            "print_info: PAD token        = 151643 '<|endoftext|>'\n",
            "print_info: LF token         = 198 'Ċ'\n",
            "print_info: FIM PRE token    = 151659 '<|fim_prefix|>'\n",
            "print_info: FIM SUF token    = 151661 '<|fim_suffix|>'\n",
            "print_info: FIM MID token    = 151660 '<|fim_middle|>'\n",
            "print_info: FIM PAD token    = 151662 '<|fim_pad|>'\n",
            "print_info: FIM REP token    = 151663 '<|repo_name|>'\n",
            "print_info: FIM SEP token    = 151664 '<|file_sep|>'\n",
            "print_info: EOG token        = 151643 '<|endoftext|>'\n",
            "print_info: EOG token        = 151645 '<|im_end|>'\n",
            "print_info: EOG token        = 151662 '<|fim_pad|>'\n",
            "print_info: EOG token        = 151663 '<|repo_name|>'\n",
            "print_info: EOG token        = 151664 '<|file_sep|>'\n",
            "print_info: max token length = 256\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: offloading 36 repeating layers to GPU\n",
            "load_tensors: offloading output layer to GPU\n",
            "load_tensors: offloaded 37/37 layers to GPU\n",
            "load_tensors:        CUDA0 model buffer size =  4076.43 MiB\n",
            "load_tensors:   CPU_Mapped model buffer size =   394.12 MiB\n",
            "......................\n",
            "llama_context: constructing llama_context\n",
            "llama_context: n_seq_max     = 1\n",
            "llama_context: n_ctx         = 8192\n",
            "llama_context: n_ctx_per_seq = 8192\n",
            "llama_context: n_batch       = 256\n",
            "llama_context: n_ubatch      = 256\n",
            "llama_context: causal_attn   = 1\n",
            "llama_context: flash_attn    = 0\n",
            "llama_context: kv_unified    = false\n",
            "llama_context: freq_base     = 5000000.0\n",
            "llama_context: freq_scale    = 1\n",
            "llama_context: n_ctx_per_seq (8192) < n_ctx_train (262144) -- the full capacity of the model will not be utilized\n",
            "llama_context:  CUDA_Host  output buffer size =     0.58 MiB\n",
            "llama_kv_cache_unified:      CUDA0 KV buffer size =  1152.00 MiB\n",
            "llama_kv_cache_unified: size = 1152.00 MiB (  8192 cells,  36 layers,  1/1 seqs), K (f16):  576.00 MiB, V (f16):  576.00 MiB\n",
            "llama_context:      CUDA0 compute buffer size =   279.00 MiB\n",
            "llama_context:  CUDA_Host compute buffer size =    12.50 MiB\n",
            "llama_context: graph nodes  = 1410\n",
            "llama_context: graph splits = 2\n",
            "common_init_from_params: added <|endoftext|> logit bias = -inf\n",
            "common_init_from_params: added <|im_end|> logit bias = -inf\n",
            "common_init_from_params: added <|fim_pad|> logit bias = -inf\n",
            "common_init_from_params: added <|repo_name|> logit bias = -inf\n",
            "common_init_from_params: added <|file_sep|> logit bias = -inf\n",
            "common_init_from_params: setting dry_penalty_last_n to ctx_size = 8192\n",
            "common_init_from_params: warming up the model with an empty run - please wait ... (--no-warmup to disable)\n",
            "main: model loaded\n",
            "main: chat template, chat_template: {%- if tools %}\n",
            "    {{- '<|im_start|>system\\n' }}\n",
            "    {%- if messages[0].role == 'system' %}\n",
            "        {{- messages[0].content + '\\n\\n' }}\n",
            "    {%- endif %}\n",
            "    {{- \"In this environment you have access to a set of tools you can use to answer the user's question. You can use one tool per message, and will receive the result of that tool use in the user's response. You use tools step-by-step to accomplish a given task, with each tool use informed by the result of the previous tool use.\\n\\nTool Use Rules\\nHere are the rules you should always follow to solve your task:\\n1. Always use the right arguments for the tools. Never use variable names as the action arguments, use the value instead.\\n2. Call a tool only when needed: do not call the search agent if you do not need information, try to solve the task yourself.\\n3. If no tool call is needed, just answer the question directly.\\n4. Never re-do a tool call that you previously did with the exact same parameters.\\n5. For tool use, MARK SURE use XML tag format as shown in the examples above. Do not use any other format.\\nNow Begin! If you solve the task correctly, you will receive a reward of $1,000,000.\\n\\n\" }}\n",
            "    {{- \"# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
            "    {%- for tool in tools %}\n",
            "        {{- \"\\n\" }}\n",
            "        {{- tool | tojson }}\n",
            "    {%- endfor %}\n",
            "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n",
            "{%- else %}\n",
            "    {%- if messages[0].role == 'system' %}\n",
            "        {{- '<|im_start|>system\\n' + messages[0].content + '<|im_end|>\\n' }}\n",
            "    {%- endif %}\n",
            "{%- endif %}\n",
            "{%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %}\n",
            "{%- for message in messages[::-1] %}\n",
            "    {%- set index = (messages|length - 1) - loop.index0 %}\n",
            "    {%- if ns.multi_step_tool and message.role == \"user\" and message.content is string and not(message.content.startswith('<tool_response>') and message.content.endswith('</tool_response>')) %}\n",
            "        {%- set ns.multi_step_tool = false %}\n",
            "        {%- set ns.last_query_index = index %}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "{%- for message in messages %}\n",
            "    {%- if message.content is string %}\n",
            "        {%- set content = message.content %}\n",
            "    {%- else %}\n",
            "        {%- set content = '' %}\n",
            "    {%- endif %}\n",
            "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) %}\n",
            "        {{- '<|im_start|>' + message.role + '\\n' + content + '<|im_end|>' + '\\n' }}\n",
            "    {%- elif message.role == \"assistant\" %}\n",
            "        {%- set reasoning_content = '' %}\n",
            "        {%- if message.reasoning_content is string %}\n",
            "            {%- set reasoning_content = message.reasoning_content %}\n",
            "        {%- else %}\n",
            "            {%- if '</think>' in content %}\n",
            "                {%- set reasoning_content = content.split('</think>')[0].rstrip('\\n').split('<think>')[-1].lstrip('\\n') %}\n",
            "                {%- set content = content.split('</think>')[-1].lstrip('\\n') %}\n",
            "            {%- endif %}\n",
            "        {%- endif %}\n",
            "        {%- if loop.index0 > ns.last_query_index %}\n",
            "            {%- if loop.last or (not loop.last and reasoning_content) %}\n",
            "                {{- '<|im_start|>' + message.role + '\\n<think>\\n' + reasoning_content.strip('\\n') + '\\n</think>\\n\\n' + content.lstrip('\\n') }}\n",
            "            {%- else %}\n",
            "                {{- '<|im_start|>' + message.role + '\\n' + content }}\n",
            "            {%- endif %}\n",
            "        {%- else %}\n",
            "            {{- '<|im_start|>' + message.role + '\\n' + content }}\n",
            "        {%- endif %}\n",
            "        {%- if message.tool_calls %}\n",
            "            {%- for tool_call in message.tool_calls %}\n",
            "                {%- if (loop.first and content) or (not loop.first) %}\n",
            "                    {{- '\\n' }}\n",
            "                {%- endif %}\n",
            "                {%- if tool_call.function %}\n",
            "                    {%- set tool_call = tool_call.function %}\n",
            "                {%- endif %}\n",
            "                {{- '<tool_call>\\n{\"name\": \"' }}\n",
            "                {{- tool_call.name }}\n",
            "                {{- '\", \"arguments\": ' }}\n",
            "                {%- if tool_call.arguments is string %}\n",
            "                    {{- tool_call.arguments }}\n",
            "                {%- else %}\n",
            "                    {{- tool_call.arguments | tojson }}\n",
            "                {%- endif %}\n",
            "                {{- '}\\n</tool_call>' }}\n",
            "            {%- endfor %}\n",
            "        {%- endif %}\n",
            "        {{- '<|im_end|>\\n' }}\n",
            "    {%- elif message.role == \"tool\" %}\n",
            "        {%- if loop.first or (messages[loop.index0 - 1].role != \"tool\") %}\n",
            "            {{- '<|im_start|>user' }}\n",
            "        {%- endif %}\n",
            "        {{- '\\n<tool_response>\\n' }}\n",
            "        {{- content }}\n",
            "        {{- '\\n</tool_response>' }}\n",
            "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
            "            {{- '<|im_end|>\\n' }}\n",
            "        {%- endif %}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "{%- if add_generation_prompt %}\n",
            "    {{- '<|im_start|>assistant\\n' }}\n",
            "{%- endif %}, example_format: '<|im_start|>system\n",
            "You are a helpful assistant<|im_end|>\n",
            "<|im_start|>user\n",
            "Hello<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Hi there<|im_end|>\n",
            "<|im_start|>user\n",
            "How are you?<|im_end|>\n",
            "<|im_start|>assistant\n",
            "'\n",
            "main: server is listening on http://127.0.0.1:34647 - starting the main loop\n",
            "\u001b[2;36m07:42:21-520374\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loaded \u001b[32m\"janhq_Jan-v1-4B-Q8_0.gguf\"\u001b[0m in \u001b[1;36m10.06\u001b[0m seconds.   \n",
            "\u001b[2;36m07:42:21-521458\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m LOADER: \u001b[32m\"llama.cpp\"\u001b[0m                                    \n",
            "\u001b[2;36m07:42:21-522259\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m TRUNCATION LENGTH: \u001b[1;36m8192\u001b[0m                                \n",
            "\u001b[2;36m07:42:21-522995\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INSTRUCTION TEMPLATE: \u001b[32m\"Custom \u001b[0m\u001b[32m(\u001b[0m\u001b[32mobtained from model \u001b[0m    \n",
            "\u001b[2;36m                \u001b[0m         \u001b[32mmetadata\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\"\u001b[0m                                             \n",
            "\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "Running on public URL: https://2496c51b8f474b3c6c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "prompt processing progress, n_past = 50, n_tokens = 50, progress = 1.000000\n",
            "prompt eval time =     362.75 ms /    50 tokens (    7.26 ms per token,   137.83 tokens per second)\n",
            "       eval time =    5835.04 ms /   249 tokens (   23.43 ms per token,    42.67 tokens per second)\n",
            "      total time =    6197.79 ms /   299 tokens\n",
            "\u001b[2;36m07:44:39-537270\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Output generated in \u001b[1;36m6.20\u001b[0m seconds \u001b[1m(\u001b[0m\u001b[1;36m39.98\u001b[0m tokens/s, \u001b[1;36m248\u001b[0m  \n",
            "\u001b[2;36m                \u001b[0m         tokens, context \u001b[1;36m50\u001b[0m, seed \u001b[1;36m1673645274\u001b[0m\u001b[1m)\u001b[0m                   \n",
            "\u001b[2;36m07:44:39-538878\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Using search query: Duolingo stock current performance \n",
            "\u001b[2;36m07:44:40-760208\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m Error downloading                                      \n",
            "\u001b[2;36m                \u001b[0m         \u001b[4;94mhttps://www.marketwatch.com/investing/stock/duol:\u001b[0m \u001b[1;36m401\u001b[0m  \n",
            "\u001b[2;36m                \u001b[0m         Client Error: HTTP Forbidden for url:                  \n",
            "\u001b[2;36m                \u001b[0m         \u001b[4;94mhttps://www.marketwatch.com/investing/stock/duol\u001b[0m       \n",
            "\u001b[2;36m07:44:43-303936\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Added \u001b[1;36m2\u001b[0m successful web search results as attachments.  \n",
            "\u001b[2;36m07:44:43-945434\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m User message truncated from \u001b[1;36m10836\u001b[0m to \u001b[1;36m7672\u001b[0m tokens.      \n",
            "\u001b[2;36m                \u001b[0m         Context full: \u001b[1;36m7680\u001b[0m input tokens \u001b[1m(\u001b[0m\u001b[1;36m8192\u001b[0m total, \u001b[1;36m512\u001b[0m for   \n",
            "\u001b[2;36m                \u001b[0m         output\u001b[1m)\u001b[0m. Increase ctx-size while loading the model to  \n",
            "\u001b[2;36m                \u001b[0m         avoid truncation.                                      \n",
            "\n",
            "prompt eval time =    8623.32 ms /  7666 tokens (    1.12 ms per token,   888.98 tokens per second)\n",
            "       eval time =   18158.66 ms /   512 tokens (   35.47 ms per token,    28.20 tokens per second)\n",
            "      total time =   26781.98 ms /  8178 tokens\n",
            "\u001b[2;36m07:45:10-761657\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Output generated in \u001b[1;36m26.81\u001b[0m seconds \u001b[1m(\u001b[0m\u001b[1;36m19.10\u001b[0m tokens/s, \u001b[1;36m512\u001b[0m \n",
            "\u001b[2;36m                \u001b[0m         tokens, context \u001b[1;36m7680\u001b[0m, seed \u001b[1;36m1158011320\u001b[0m\u001b[1m)\u001b[0m                 \n",
            "\n",
            "prompt eval time =     420.35 ms /   514 tokens (    0.82 ms per token,  1222.79 tokens per second)\n",
            "       eval time =   32359.37 ms /  1175 tokens (   27.54 ms per token,    36.31 tokens per second)\n",
            "      total time =   32779.72 ms /  1689 tokens\n",
            "\u001b[2;36m07:47:11-403841\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Output generated in \u001b[1;36m32.79\u001b[0m seconds \u001b[1m(\u001b[0m\u001b[1;36m35.81\u001b[0m tokens/s, \u001b[1;36m1174\u001b[0m\n",
            "\u001b[2;36m                \u001b[0m         tokens, context \u001b[1;36m515\u001b[0m, seed \u001b[1;36m1315820843\u001b[0m\u001b[1m)\u001b[0m                  \n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!apt-get -y install -qq aria2\n",
        "\n",
        "!git clone -b V20250815 https://github.com/Troyanovsky/text-generation-webui\n",
        "%cd /content/text-generation-webui\n",
        "!pip install -r requirements/full/requirements.txt\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/bartowski/janhq_Jan-v1-4B-GGUF/resolve/main/janhq_Jan-v1-4B-Q8_0.gguf?download=true -d /content/text-generation-webui/user_data/models -o janhq_Jan-v1-4B-Q8_0.gguf\n",
        "%cd /content/text-generation-webui\n",
        "!python server.py --share --n-gpu-layers 10000 --model janhq_Jan-v1-4B-Q8_0.gguf --n_ctx 12288"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+dQQDKYFuImcvxP/rYea1",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}